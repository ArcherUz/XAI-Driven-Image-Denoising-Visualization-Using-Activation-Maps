{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNCNN_GradCam_version1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EuG-_epXlvid",
        "outputId": "9f98708f-bb48-43fd-cc7f-9a803bc5f1d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nsaliency maps by Grad-Cam saliency algorithm from https://github.com/idiap/fullgrad-saliency\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"\n",
        "saliency maps by Grad-Cam saliency algorithm from https://github.com/idiap/fullgrad-saliency\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oks_gHByl-uf",
        "outputId": "4d506ace-2bca-4f92-a3d4-0e6ca9d10339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model_path='/content/drive/My Drive/DNCNN_logs'\n",
        "data_path = '/content/drive/My Drive/data'\n",
        "dataset = '/Set12'\n",
        "test_noiseL = 25"
      ],
      "metadata": {
        "id": "TIn4v10TmcWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from skimage.metrics import peak_signal_noise_ratio\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "6U4g-Tpemigt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "I3wKQmiMm1L-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DnCNN(nn.Module):\n",
        "    def __init__(self, channels, num_of_layers=17):\n",
        "        super(DnCNN, self).__init__()\n",
        "        kernel_size = 3\n",
        "        padding = 1\n",
        "        features = 64\n",
        "        layers = []\n",
        "        layers.append(nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "        for _ in range(num_of_layers-2):\n",
        "            layers.append(nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "            layers.append(nn.BatchNorm2d(features))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "        layers.append(nn.Conv2d(in_channels=features, out_channels=channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "        self.dncnn = nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        out = self.dncnn(x)\n",
        "        return out\n",
        "\n",
        "def batch_PSNR(img, imclean, data_range):\n",
        "    Img = img.data.cpu().numpy().astype(np.float32)\n",
        "    Iclean = imclean.data.cpu().numpy().astype(np.float32)\n",
        "    PSNR = 0\n",
        "    for i in range(Img.shape[0]):\n",
        "        PSNR += peak_signal_noise_ratio(Iclean[i,:,:,:], Img[i,:,:,:], data_range=data_range)\n",
        "    return (PSNR/Img.shape[0])"
      ],
      "metadata": {
        "id": "PSlgbFmcmmAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GradCAMExtractor:\n",
        "    #Extract tensors needed for Gradcam using hooks\n",
        "    \n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "        self.features = None\n",
        "        self.feature_grads = None\n",
        "\n",
        "        prev_module = None\n",
        "        self.target_module = None\n",
        "\n",
        "        # Iterate through layers\n",
        "        for m in self.model.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                prev_module = m\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                self.target_module = prev_module\n",
        "                break\n",
        "\n",
        "        if self.target_module is not None:\n",
        "            # Register feature-gradient and feature hooks for each layer\n",
        "            handle_g = self.target_module.register_backward_hook(self._extract_layer_grads)\n",
        "            handle_f = self.target_module.register_forward_hook(self._extract_layer_features)\n",
        "\n",
        "    def _extract_layer_grads(self, module, in_grad, out_grad):\n",
        "        # function to collect the gradient outputs\n",
        "        self.feature_grads = out_grad[0]\n",
        "    \n",
        "    def _extract_layer_features(self, module, input, output):\n",
        "        # function to collect the layer outputs\n",
        "        self.features = output\n",
        "\n",
        "    def getFeaturesAndGrads(self, x, target_class):\n",
        "\n",
        "        out = self.model(x)\n",
        "\n",
        "        if target_class is None:\n",
        "            target_class = out.data.max(1, keepdim=True)[1]\n",
        "\n",
        "        #output_scalar = -1. * F.nll_loss(out, target_class.flatten(), reduction='sum')\n",
        "        criterion = nn.MSELoss(size_average=False)\n",
        "        criterion.cuda()\n",
        "        noise = torch.FloatTensor(target_class.size()).normal_(mean=0, std=test_noiseL/255.)\n",
        "        loss = criterion(target_class, noise.cuda()) / (x.size()[0]*2)\n",
        "\n",
        "        # Compute gradients\n",
        "        self.model.zero_grad()\n",
        "        #output_scalar.backward()\n",
        "        loss.backward()\n",
        "\n",
        "        return self.features, self.feature_grads\n",
        "\n",
        "\n",
        "class GradCAM():\n",
        "    \"\"\"\n",
        "    Compute GradCAM \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.model_ext = GradCAMExtractor(self.model)\n",
        "\n",
        "\n",
        "    def saliency(self, image, target_class):\n",
        "        #Simple FullGrad saliency\n",
        "        \n",
        "        self.model.eval()\n",
        "        features, intermed_grad = self.model_ext.getFeaturesAndGrads(image, target_class=target_class)\n",
        "\n",
        "        # GradCAM computation\n",
        "        grads = intermed_grad.mean(dim=(2,3), keepdim=True)\n",
        "        cam = (F.relu(features)* grads).sum(1, keepdim=True)\n",
        "        cam_resized = F.interpolate(F.relu(cam), size=image.size(2), mode='bilinear', align_corners=True)\n",
        "        return cam_resized"
      ],
      "metadata": {
        "id": "N2EVGpuOn4mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(data):\n",
        "    return data/255."
      ],
      "metadata": {
        "id": "wAnG4vgMoETM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_saliency_map(image, saliency_map, filename):\n",
        "    \"\"\"\n",
        "    save saliency map on image\n",
        "    Image: tensor of size (3, H, W)\n",
        "    saliency_map: Tensor of size (1, H, W)\n",
        "    filename: string with complete path and file extension\n",
        "    \"\"\"\n",
        "    image = image.data.cpu().numpy()\n",
        "    saliency_map = saliency_map.data.cpu().numpy()\n",
        "\n",
        "    saliency_map = saliency_map - saliency_map.min()\n",
        "    saliency_map = saliency_map / saliency_map.max()\n",
        "    saliency_map = saliency_map.clip(0, 1)\n",
        "\n",
        "    saliency_map = np.uint8(saliency_map * 255).transpose(1, 2, 0)\n",
        "    saliency_map = cv2.resize(saliency_map, (224, 224))\n",
        "\n",
        "    image = np.uint8(image * 255).transpose(1, 2, 0)\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "\n",
        "    # Apply JET colormap\n",
        "    color_heatmap = cv2.applyColorMap(saliency_map, cv2.COLORMAP_JET)\n",
        "\n",
        "    # Combine image with heatmap\n",
        "    img_with_heatmap = np.float32(color_heatmap) + np.float32(image)\n",
        "    img_with_heatmap = img_with_heatmap / np.max(img_with_heatmap)\n",
        "\n",
        "    cv2.imwrite(filename, np.uint8(255 * img_with_heatmap))"
      ],
      "metadata": {
        "id": "RLs9UOm6oVSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/drive/My Drive/DNCNN_saliency_maps/grad_cam'\n",
        "\n",
        "print('Loading model ...\\n')\n",
        "net = DnCNN(channels=1, num_of_layers=17)\n",
        "device_ids = [0]\n",
        "model = nn.DataParallel(net, device_ids=device_ids).cuda()\n",
        "model.load_state_dict(torch.load(os.path.join(trained_model_path + '/DnCNN-S-25', 'net.pth')))\n",
        "model.eval()\n",
        "# load data info\n",
        "print('Loading data info ...\\n')\n",
        "files_source = glob.glob(os.path.join(data_path + dataset, '*.png'))\n",
        "files_source.sort() #a list with file names\n",
        "\n",
        "\n",
        "saliency_methods = GradCAM(model)\n",
        "\n",
        "def compute_saliency_and_save():\n",
        "    for f in files_source:\n",
        "      Img = cv2.imread(f)\n",
        "      Img = normalize(np.float32(Img[:,:,0]))\n",
        "      Img = np.expand_dims(Img, 0)\n",
        "      Img = np.expand_dims(Img, 1)\n",
        "      ISource = torch.Tensor(Img)\n",
        "      noise = torch.FloatTensor(ISource.size()).normal_(mean=0, std=test_noiseL/255.)\n",
        "      INoisy = ISource + noise\n",
        "      ISource, INoisy = Variable(ISource.cuda()), Variable(INoisy.cuda())\n",
        "      INoisy = INoisy.requires_grad_()\n",
        "\n",
        "      # Compute saliency maps for the input data\n",
        "      saliency_map = saliency_methods.saliency(INoisy, (INoisy-model(INoisy)))\n",
        "\n",
        "      # Save saliency maps\n",
        "      for i in range(INoisy.size(0)):\n",
        "        filename = str(i)\n",
        "        image = INoisy[i]\n",
        "        save_saliency_map(image, saliency_map[i], filename + '_'  + '.jpg')\n",
        "\n",
        "compute_saliency_and_save()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "0ZfjCBg5m2-1",
        "outputId": "e07c4c84-afd2-414a-e1ad-0ce395cb89b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model ...\n",
            "\n",
            "Loading data info ...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-85ef31ee7ff4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0msave_saliency_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaliency_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mcompute_saliency_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-85ef31ee7ff4>\u001b[0m in \u001b[0;36mcompute_saliency_and_save\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0;31m# Compute saliency maps for the input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0msaliency_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaliency_methods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaliency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINoisy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mINoisy\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINoisy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0;31m# Save saliency maps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-a817aa76ffdf>\u001b[0m in \u001b[0;36msaliency\u001b[0;34m(self, image, target_class)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# GradCAM computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintermed_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mcam_resized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'mean'"
          ]
        }
      ]
    }
  ]
}