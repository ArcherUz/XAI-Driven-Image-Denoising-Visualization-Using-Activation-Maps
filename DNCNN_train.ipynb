{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "colab version of DNCNN https://github.com/SaoYan/DnCNN-PyTorch using GPU\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "njjRELXmYjYX",
        "outputId": "c08bf54d-d9cb-449a-9fd2-64bd541d144c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ncolab version of DNCNN https://github.com/SaoYan/DnCNN-PyTorch using GPU\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVDZY5W04HmD",
        "outputId": "89768c0d-041e-40f5-b41d-b4cdbf0a6dc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdX2hAE5NsvA",
        "outputId": "35598995-e892-4d65-91bc-6acb45379ef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08FqRWiq0_A8"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import os\n",
        "import os.path\n",
        "import random\n",
        "import h5py\n",
        "import cv2\n",
        "import glob\n",
        "import torch.utils.data as udata\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torchvision import utils\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2CTc5Vgq0C2",
        "outputId": "66d134c6-6091-415c-83cc-4b8c54c50e0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda Tesla P100-PCIE-16GB\n"
          ]
        }
      ],
      "source": [
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        print(torch.device('cuda'), torch.cuda.get_device_name(0))\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        print(torch.device('cpu'))\n",
        "        return torch.device('cpu')\n",
        "\n",
        "device = get_default_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuH0mUzcPs94"
      },
      "outputs": [],
      "source": [
        "#From utils.py\n",
        "def data_augmentation(image, mode):\n",
        "    out = np.transpose(image, (1,2,0))\n",
        "    if mode == 0:\n",
        "        # original\n",
        "        out = out\n",
        "    elif mode == 1:\n",
        "        # flip up and down\n",
        "        out = np.flipud(out)\n",
        "    elif mode == 2:\n",
        "        # rotate counterwise 90 degree\n",
        "        out = np.rot90(out)\n",
        "    elif mode == 3:\n",
        "        # rotate 90 degree and flip up and down\n",
        "        out = np.rot90(out)\n",
        "        out = np.flipud(out)\n",
        "    elif mode == 4:\n",
        "        # rotate 180 degree\n",
        "        out = np.rot90(out, k=2)\n",
        "    elif mode == 5:\n",
        "        # rotate 180 degree and flip\n",
        "        out = np.rot90(out, k=2)\n",
        "        out = np.flipud(out)\n",
        "    elif mode == 6:\n",
        "        # rotate 270 degree\n",
        "        out = np.rot90(out, k=3)\n",
        "    elif mode == 7:\n",
        "        # rotate 270 degree and flip\n",
        "        out = np.rot90(out, k=3)\n",
        "        out = np.flipud(out)\n",
        "    return np.transpose(out, (2,0,1))\n",
        "\n",
        "\n",
        "#From dataset.py\n",
        "def normalize(data):\n",
        "    return data/255.\n",
        "\n",
        "def Im2Patch(img, win, stride=1):\n",
        "    k = 0\n",
        "    endc = img.shape[0]\n",
        "    endw = img.shape[1]\n",
        "    endh = img.shape[2]\n",
        "    patch = img[:, 0:endw-win+0+1:stride, 0:endh-win+0+1:stride]\n",
        "    TotalPatNum = patch.shape[1] * patch.shape[2]\n",
        "    Y = np.zeros([endc, win*win,TotalPatNum], np.float32)\n",
        "    for i in range(win):\n",
        "        for j in range(win):\n",
        "            patch = img[:,i:endw-win+i+1:stride,j:endh-win+j+1:stride]\n",
        "            Y[:,k,:] = np.array(patch[:]).reshape(endc, TotalPatNum)\n",
        "            k = k + 1\n",
        "    return Y.reshape([endc, win, win, TotalPatNum])\n",
        "\n",
        "def prepare_data(data_path, patch_size, stride, aug_times=1):\n",
        "    # train\n",
        "    print('process training data')\n",
        "    scales = [1, 0.9, 0.8, 0.7]\n",
        "    files = glob.glob(os.path.join(data_path, 'train', '*.png'))\n",
        "    files.sort()\n",
        "    h5f = h5py.File('train.h5', 'w')\n",
        "    train_num = 0\n",
        "    for i in range(len(files)):\n",
        "        img = cv2.imread(files[i])\n",
        "        h, w, c = img.shape\n",
        "        for k in range(len(scales)):\n",
        "            Img = cv2.resize(img, (int(h*scales[k]), int(w*scales[k])), interpolation=cv2.INTER_CUBIC)\n",
        "            Img = np.expand_dims(Img[:,:,0].copy(), 0)\n",
        "            Img = np.float32(normalize(Img))\n",
        "            patches = Im2Patch(Img, win=patch_size, stride=stride)\n",
        "            print(\"file: %s scale %.1f # samples: %d\" % (files[i], scales[k], patches.shape[3]*aug_times))\n",
        "            for n in range(patches.shape[3]):\n",
        "                data = patches[:,:,:,n].copy()\n",
        "                h5f.create_dataset(str(train_num), data=data)\n",
        "                train_num += 1\n",
        "                for m in range(aug_times-1):\n",
        "                    data_aug = data_augmentation(data, np.random.randint(1,8))\n",
        "                    h5f.create_dataset(str(train_num)+\"_aug_%d\" % (m+1), data=data_aug)\n",
        "                    train_num += 1\n",
        "    h5f.close()\n",
        "    # val\n",
        "    print('\\nprocess validation data')\n",
        "    files.clear()\n",
        "    files = glob.glob(os.path.join(data_path, 'Set12', '*.png'))\n",
        "    files.sort()\n",
        "    h5f = h5py.File('val.h5', 'w')\n",
        "    val_num = 0\n",
        "    for i in range(len(files)):\n",
        "        print(\"file: %s\" % files[i])\n",
        "        img = cv2.imread(files[i])\n",
        "        img = np.expand_dims(img[:,:,0], 0)\n",
        "        img = np.float32(normalize(img))\n",
        "        h5f.create_dataset(str(val_num), data=img)\n",
        "        val_num += 1\n",
        "    h5f.close()\n",
        "    print('training set, # samples %d\\n' % train_num)\n",
        "    print('val set, # samples %d\\n' % val_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAhYIgri9F73"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT5RsF-f2BOE",
        "outputId": "de8a0389-2e2f-4d97-eb3d-569d0871fb59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "process training data\n",
            "file: /content/drive/My Drive/data/train/test_001.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_001.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_001.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_001.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_002.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_002.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_002.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_002.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_003.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_003.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_003.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_003.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_004.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_004.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_004.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_004.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_005.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_005.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_005.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_005.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_006.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_006.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_006.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_006.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_007.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_007.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_007.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_007.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_008.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_008.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_008.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_008.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_009.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_009.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_009.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_009.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_010.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_010.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_010.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_010.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_011.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_011.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_011.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_011.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_012.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_012.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_012.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_012.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_013.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_013.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_013.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_013.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_014.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_014.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_014.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_014.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_015.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_015.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_015.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_015.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_016.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_016.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_016.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_016.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_017.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_017.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_017.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_017.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_018.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_018.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_018.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_018.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_019.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_019.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_019.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_019.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_020.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_020.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_020.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_020.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_021.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_021.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_021.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_021.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_022.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_022.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_022.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_022.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_023.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_023.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_023.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_023.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_024.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_024.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_024.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_024.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_025.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_025.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_025.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_025.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_026.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_026.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_026.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_026.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_027.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_027.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_027.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_027.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_028.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_028.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_028.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_028.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_029.png scale 1.0 # samples: 225\n",
            "file: /content/drive/My Drive/data/train/test_029.png scale 0.9 # samples: 169\n",
            "file: /content/drive/My Drive/data/train/test_029.png scale 0.8 # samples: 121\n",
            "file: /content/drive/My Drive/data/train/test_029.png scale 0.7 # samples: 81\n",
            "file: /content/drive/My Drive/data/train/test_030.png scale 1.0 # samples: 225\n"
          ]
        }
      ],
      "source": [
        "#prepare data, DnCNN with known noise level, only run once\n",
        "prepare_data(data_path='/content/drive/My Drive/data', patch_size=40, stride=10, aug_times=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = \"/content/drive/My Drive/\""
      ],
      "metadata": {
        "id": "EOeWU-ll0XT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7N26IlYz6GV8"
      },
      "outputs": [],
      "source": [
        "class Dataset(udata.Dataset):\n",
        "    def __init__(self, train=True):\n",
        "        super(Dataset, self).__init__()\n",
        "        self.train = train\n",
        "        if self.train:\n",
        "            h5f = h5py.File('train.h5', 'r')\n",
        "        else:\n",
        "            h5f = h5py.File('val.h5', 'r')\n",
        "        self.keys = list(h5f.keys())\n",
        "        random.shuffle(self.keys)\n",
        "        h5f.close()\n",
        "    def __len__(self):\n",
        "        return len(self.keys)\n",
        "    def __getitem__(self, index):\n",
        "        if self.train:\n",
        "            h5f = h5py.File('train.h5', 'r')\n",
        "        else:\n",
        "            h5f = h5py.File('val.h5', 'r')\n",
        "        key = self.keys[index]\n",
        "        data = np.array(h5f[key])\n",
        "        h5f.close()\n",
        "        return torch.Tensor(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSXdF37r_XYc"
      },
      "outputs": [],
      "source": [
        "class DnCNN(nn.Module):\n",
        "    def __init__(self, channels, num_of_layers=17):\n",
        "        super(DnCNN, self).__init__()\n",
        "        kernel_size = 3\n",
        "        padding = 1\n",
        "        features = 64\n",
        "        layers = []\n",
        "        layers.append(nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "        for _ in range(num_of_layers-2):\n",
        "            layers.append(nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "            layers.append(nn.BatchNorm2d(features))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "        layers.append(nn.Conv2d(in_channels=features, out_channels=channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "        self.dncnn = nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        out = self.dncnn(x)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qb_lpjxISrq"
      },
      "outputs": [],
      "source": [
        "#From utils.py\n",
        "from skimage.metrics import peak_signal_noise_ratio\n",
        "def weights_init_kaiming(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n",
        "    elif classname.find('Linear') != -1:\n",
        "        nn.init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        # nn.init.uniform(m.weight.data, 1.0, 0.02)\n",
        "        m.weight.data.normal_(mean=0, std=math.sqrt(2./9./64.)).clamp_(-0.025,0.025)\n",
        "        nn.init.constant(m.bias.data, 0.0)\n",
        "\n",
        "def batch_PSNR(img, imclean, data_range):\n",
        "    Img = img.data.cpu().numpy().astype(np.float32)\n",
        "    Iclean = imclean.data.cpu().numpy().astype(np.float32)\n",
        "    PSNR = 0\n",
        "    for i in range(Img.shape[0]):\n",
        "        PSNR += peak_signal_noise_ratio(Iclean[i,:,:,:], Img[i,:,:,:], data_range=data_range)\n",
        "    return (PSNR/Img.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1vZdbG151dW"
      },
      "outputs": [],
      "source": [
        "#From Main.py main()\n",
        "# Load dataset\n",
        "print('Loading dataset ...\\n')\n",
        "dataset_train = Dataset(train=True)\n",
        "dataset_val = Dataset(train=False)\n",
        "loader_train = DataLoader(dataset=dataset_train, num_workers=4, batch_size=128, shuffle=True)\n",
        "print(\"# of training samples: %d\\n\" % int(len(dataset_train)))\n",
        "# Build model\n",
        "net = DnCNN(channels=1, num_of_layers=17)\n",
        "net.apply(weights_init_kaiming)\n",
        "criterion = nn.MSELoss(size_average=False)\n",
        "\n",
        "# Move to GPU\n",
        "if cuda:\n",
        "\n",
        "  device_ids = [0]\n",
        "  model = nn.DataParallel(net, device_ids=device_ids).cuda()\n",
        "  criterion.cuda()\n",
        "\"\"\"\n",
        "\n",
        "device_ids = [0]\n",
        "model = nn.DataParallel(net, device_ids=device_ids)\n",
        "\"\"\"\n",
        "\n",
        "# Optimizer\n",
        "learning_rate = 1e-3\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWcCetOvDqAr"
      },
      "outputs": [],
      "source": [
        "from tensorboardX import SummaryWriter\n",
        "import argparse\n",
        "\n",
        "# parser = argparse.ArgumentParser(description=\"DnCNN\")\n",
        "# opt = parser.parse_args()\n",
        "\n",
        "# training\n",
        "writer = SummaryWriter(\"logs\")\n",
        "step = 0\n",
        "train_epoch = 1\n",
        "milestone = 30 #When to decay learning rate; should be less than epochs\n",
        "noise_level = 25\n",
        "for epoch in range(train_epoch):\n",
        "    if epoch < milestone:\n",
        "        current_lr = learning_rate\n",
        "    else:\n",
        "        current_lr = learning_rate / 10.\n",
        "    \n",
        "    # set learning rate\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = current_lr\n",
        "    print('learning rate %f' % current_lr)\n",
        "    \n",
        "    # train\n",
        "    for i, data in enumerate(loader_train, 0):\n",
        "        # training step\n",
        "        model.train()\n",
        "        model.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "        img_train = data\n",
        "        noise = torch.FloatTensor(img_train.size()).normal_(mean=0, std=noise_level/255.)\n",
        "        imgn_train = img_train + noise\n",
        "        # save img_train imgn_train, out_train\n",
        "        \n",
        "        img_train, imgn_train = Variable(img_train.cuda()), Variable(imgn_train.cuda())\n",
        "        \n",
        "        noise = Variable(noise.cuda())\n",
        "        out_train = model(imgn_train)\n",
        "        loss = criterion(out_train, noise) / (imgn_train.size()[0]*2)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # results\n",
        "        model.eval()\n",
        "        out_train = torch.clamp(imgn_train-model(imgn_train), 0., 1.)\n",
        "        psnr_train = batch_PSNR(out_train, img_train, 1.)\n",
        "        print(\"[epoch %d][%d/%d] loss: %.4f PSNR_train: %.4f\" %\n",
        "            (epoch+1, i+1, len(loader_train), loss.item(), psnr_train))\n",
        "        # if you are using older version of PyTorch, you may need to change loss.item() to loss.data[0]\n",
        "        if step % 10 == 0:\n",
        "            # Log the scalar values\n",
        "            writer.add_scalar('loss', loss.item(), step)\n",
        "            writer.add_scalar('PSNR on training data', psnr_train, step)\n",
        "        step += 1\n",
        "    ## the end of each epoch\n",
        "    model.eval()\n",
        "\n",
        "    # validate\n",
        "    val_noiseL = 25\n",
        "    psnr_val = 0\n",
        "    with torch.no_grad():\n",
        "      for k in range(len(dataset_val)):\n",
        "          img_val = torch.unsqueeze(dataset_val[k], 0)\n",
        "          noise = torch.FloatTensor(img_val.size()).normal_(mean=0, std=val_noiseL/255.)\n",
        "          imgn_val = img_val + noise\n",
        "          img_val, imgn_val = Variable(img_val.cuda()), Variable(imgn_val.cuda(), volatile=True)\n",
        "          out_val = torch.clamp(imgn_val-model(imgn_val), 0., 1.)\n",
        "          psnr_val += batch_PSNR(out_val, img_val, 1.)\n",
        "    psnr_val /= len(dataset_val)\n",
        "    print(\"\\n[epoch %d] PSNR_val: %.4f\" % (epoch+1, psnr_val))\n",
        "    writer.add_scalar('PSNR on validation data', psnr_val, epoch)\n",
        "    # log the images\n",
        "    out_train = torch.clamp(imgn_train-model(imgn_train), 0., 1.)\n",
        "    Img = utils.make_grid(img_train.data, nrow=8, normalize=True, scale_each=True)\n",
        "    Imgn = utils.make_grid(imgn_train.data, nrow=8, normalize=True, scale_each=True)\n",
        "    Irecon = utils.make_grid(out_train.data, nrow=8, normalize=True, scale_each=True)\n",
        "    writer.add_image('clean image', Img, epoch)\n",
        "    writer.add_image('noisy image', Imgn, epoch)\n",
        "    writer.add_image('reconstructed image', Irecon, epoch)\n",
        "    # save model\n",
        "    #torch.save(Disc.state_dict(), save_dir + 'model/disc_params.pkl')\n",
        "    torch.save(model.state_dict(), save_dir + 'savedncnn/net.pth')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "DNCNN_train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}