{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNCNN_fullgrad_version1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "saliency maps by FullGrad saliency algorithm from https://github.com/idiap/fullgrad-saliency\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TvOL8ilDNhsR",
        "outputId": "1c51b822-c088-45f9-8f9e-aca227489804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nsaliency maps by FullGrad saliency algorithm from https://github.com/idiap/fullgrad-saliency\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, utils, models\n",
        "import os\n",
        "import glob\n",
        "from skimage.metrics import peak_signal_noise_ratio\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "JRu49Z7Vhiyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEoE1-LEwEPz",
        "outputId": "1435de72-78bc-4f9c-cd5c-c3cd38f6e5a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "ISxnqk5hi0ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DnCNN(nn.Module):\n",
        "    def __init__(self, channels, num_of_layers=17):\n",
        "        super(DnCNN, self).__init__()\n",
        "        kernel_size = 3\n",
        "        padding = 1\n",
        "        features = 64\n",
        "        layers = []\n",
        "        layers.append(nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "        for _ in range(num_of_layers-2):\n",
        "            layers.append(nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "            layers.append(nn.BatchNorm2d(features))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "        layers.append(nn.Conv2d(in_channels=features, out_channels=channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "        self.dncnn = nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        out = self.dncnn(x)\n",
        "        return out\n",
        "\n",
        "def batch_PSNR(img, imclean, data_range):\n",
        "    Img = img.data.cpu().numpy().astype(np.float32)\n",
        "    Iclean = imclean.data.cpu().numpy().astype(np.float32)\n",
        "    PSNR = 0\n",
        "    for i in range(Img.shape[0]):\n",
        "        PSNR += peak_signal_noise_ratio(Iclean[i,:,:,:], Img[i,:,:,:], data_range=data_range)\n",
        "    return (PSNR/Img.shape[0])\n"
      ],
      "metadata": {
        "id": "w4HkZkKcnwnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FullGradExtractor:\n",
        "    #Extract tensors needed for FullGrad using hooks\n",
        "    \n",
        "    def __init__(self, model, im_size = (1,224,224)):\n",
        "        self.model = model\n",
        "        self.im_size = im_size\n",
        "\n",
        "        self.biases = []\n",
        "        self.feature_grads = []\n",
        "        self.grad_handles = []\n",
        "\n",
        "        # Iterate through layers\n",
        "        for m in self.model.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear) or isinstance(m, nn.BatchNorm2d):\n",
        "                \n",
        "                # Register feature-gradient hooks for each layer\n",
        "                handle_g = m.register_backward_hook(self._extract_layer_grads)\n",
        "                self.grad_handles.append(handle_g)\n",
        "\n",
        "                # Collect model biases\n",
        "                b = self._extract_layer_bias(m)\n",
        "                if (b is not None): self.biases.append(b)\n",
        "\n",
        "\n",
        "    def _extract_layer_bias(self, module):\n",
        "        # extract bias of each layer\n",
        "\n",
        "        # for batchnorm, the overall \"bias\" is different \n",
        "        # from batchnorm bias parameter. \n",
        "        # Let m -> running mean, s -> running std\n",
        "        # Let w -> BN weights, b -> BN bias\n",
        "        # Then, ((x - m)/s)*w + b = x*w/s + (- m*w/s + b) \n",
        "        # Thus (-m*w/s + b) is the effective bias of batchnorm\n",
        "\n",
        "        if isinstance(module, nn.BatchNorm2d):\n",
        "            b = - (module.running_mean * module.weight \n",
        "                    / torch.sqrt(module.running_var + module.eps)) + module.bias\n",
        "            return b.data\n",
        "        elif module.bias is None:\n",
        "            return None\n",
        "        else:\n",
        "            return module.bias.data\n",
        "\n",
        "    def getBiases(self):\n",
        "        # dummy function to get biases\n",
        "        return self.biases\n",
        "\n",
        "    def _extract_layer_grads(self, module, in_grad, out_grad):\n",
        "        # function to collect the gradient outputs\n",
        "        # from each layer\n",
        "\n",
        "        if not module.bias is None:\n",
        "            self.feature_grads.append(out_grad[0])\n",
        "\n",
        "    def getFeatureGrads(self, x, output_scalar):\n",
        "        \n",
        "        # Empty feature grads list \n",
        "        self.feature_grads = []\n",
        "\n",
        "        self.model.zero_grad()\n",
        "        # Gradients w.r.t. input\n",
        "        input_gradients = torch.autograd.grad(outputs = output_scalar, inputs = x)[0]\n",
        "\n",
        "        return input_gradients, self.feature_grads"
      ],
      "metadata": {
        "id": "FyGIyAJ3OJEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eroUWPoNSQB"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\" Implement FullGrad saliency algorithm \"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from math import isclose\n",
        "\n",
        "\n",
        "class FullGrad():\n",
        "    \"\"\"\n",
        "    Compute FullGrad saliency map and full gradient decomposition\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, im_size = (1,256,256) ):\n",
        "        self.model = model\n",
        "        self.im_size = (1,) + im_size\n",
        "        self.model_ext = FullGradExtractor(model, im_size)\n",
        "        self.biases = self.model_ext.getBiases()\n",
        "        self.checkCompleteness()\n",
        "\n",
        "    def checkCompleteness(self):\n",
        "        \"\"\"\n",
        "        Check if completeness property is satisfied. If not, it usually means that\n",
        "        some bias gradients are not computed (e.g.: implicit biases of non-linearities).\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        cuda = torch.cuda.is_available()\n",
        "        device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "\n",
        "        #Random input image\n",
        "        input = torch.randn(self.im_size).to(device)\n",
        "\n",
        "        # Get raw outputs\n",
        "        self.model.eval()\n",
        "        raw_output = self.model(input)\n",
        "\n",
        "        # Compute full-gradients and add them up\n",
        "        input_grad, bias_grad = self.fullGradientDecompose(input, target_class=None)\n",
        "\n",
        "        fullgradient_sum = (input_grad * input).sum()\n",
        "        for i in range(len(bias_grad)):\n",
        "            fullgradient_sum += bias_grad[i].sum()\n",
        "\n",
        "        # Compare raw output and full gradient sum\n",
        "        err_message = \"\\nThis is due to incorrect computation of bias-gradients.\"\n",
        "        err_string = \"Completeness test failed! Raw output = \" + str(raw_output.max().item()) + \" Full-gradient sum = \" + str(fullgradient_sum.item())\n",
        "        assert isclose(raw_output.max().item(), fullgradient_sum.item(), rel_tol=1e-4), err_string + err_message\n",
        "        print('Completeness test passed for FullGrad.')\n",
        "\n",
        "\n",
        "    def fullGradientDecompose(self, image, target_class=None):\n",
        "        \"\"\"\n",
        "        Compute full-gradient decomposition for an image\n",
        "        \"\"\"\n",
        "\n",
        "        self.model.eval()\n",
        "        image = image.requires_grad_()\n",
        "        out = self.model(image)\n",
        "\n",
        "        if target_class is None:\n",
        "            target_class = out.data.max(1, keepdim=True)[1]\n",
        "\n",
        "        # Select the output unit corresponding to the target class\n",
        "        # -1 compensates for negation in nll_loss function\n",
        "        #output_scalar = -1. * F.nll_loss(out, target_class.flatten(), reduction='sum')\n",
        "        output_scalar = -1. * F.nll_loss(torch.squeeze(out, 1), torch.squeeze(target_class, 1), reduction='sum')\n",
        "\n",
        "        input_gradient, feature_gradients = self.model_ext.getFeatureGrads(image, output_scalar)\n",
        "\n",
        "        # Compute feature-gradients \\times bias \n",
        "        bias_times_gradients = []\n",
        "        L = len(self.biases)\n",
        "\n",
        "        for i in range(L):\n",
        "\n",
        "            # feature gradients are indexed backwards \n",
        "            # because of backprop\n",
        "            g = feature_gradients[L-1-i]\n",
        "\n",
        "            # reshape bias dimensionality to match gradients\n",
        "            bias_size = [1] * len(g.size())\n",
        "            bias_size[1] = self.biases[i].size(0)\n",
        "            b = self.biases[i].view(tuple(bias_size))\n",
        "            \n",
        "            bias_times_gradients.append(g * b.expand_as(g))\n",
        "\n",
        "        return input_gradient, bias_times_gradients\n",
        "\n",
        "    def _postProcess(self, input, eps=1e-6):\n",
        "        # Absolute value\n",
        "        input = abs(input)\n",
        "\n",
        "        # Rescale operations to ensure gradients lie between 0 and 1\n",
        "        flatin = input.view((input.size(0),-1))\n",
        "        temp, _ = flatin.min(1, keepdim=True)\n",
        "        input = input - temp.unsqueeze(1).unsqueeze(1)\n",
        "\n",
        "        flatin = input.view((input.size(0),-1))\n",
        "        temp, _ = flatin.max(1, keepdim=True)\n",
        "        input = input / (temp.unsqueeze(1).unsqueeze(1) + eps)\n",
        "        return input\n",
        "\n",
        "    def saliency(self, image, target_class=None):\n",
        "        #FullGrad saliency\n",
        "\n",
        "        self.model.eval()\n",
        "        input_grad, bias_grad = self.fullGradientDecompose(image, target_class=target_class)\n",
        "\n",
        "        # Input-gradient * image\n",
        "        grd = input_grad * image\n",
        "        gradient = self._postProcess(grd).sum(1, keepdim=True)\n",
        "        cam = gradient\n",
        "\n",
        "        im_size = image.size()\n",
        "\n",
        "        # Aggregate Bias-gradients\n",
        "        for i in range(len(bias_grad)):\n",
        "\n",
        "            # Select only Conv layers\n",
        "            if len(bias_grad[i].size()) == len(im_size): \n",
        "                temp = self._postProcess(bias_grad[i])\n",
        "                gradient = F.interpolate(temp, size=(im_size[2], im_size[3]), mode = 'bilinear', align_corners=True)\n",
        "                cam += gradient.sum(1, keepdim=True)\n",
        "\n",
        "        return cam\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(data):\n",
        "    return data/255."
      ],
      "metadata": {
        "id": "A3BjuwTguWOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_saliency_map(image, saliency_map, filename):\n",
        "    \"\"\"\n",
        "    save saliency map on image\n",
        "    Image: tensor of size (3, H, W)\n",
        "    saliency_map: Tensor of size (1, H, W)\n",
        "    filename: string with complete path and file extension\n",
        "    \"\"\"\n",
        "    image = image.data.cpu().numpy()\n",
        "    saliency_map = saliency_map.data.cpu().numpy()\n",
        "\n",
        "    saliency_map = saliency_map - saliency_map.min()\n",
        "    saliency_map = saliency_map / saliency_map.max()\n",
        "    saliency_map = saliency_map.clip(0, 1)\n",
        "\n",
        "    saliency_map = np.uint8(saliency_map * 255).transpose(1, 2, 0)\n",
        "    saliency_map = cv2.resize(saliency_map, (224, 224))\n",
        "\n",
        "    image = np.uint8(image * 255).transpose(1, 2, 0)\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "\n",
        "    # Apply JET colormap\n",
        "    color_heatmap = cv2.applyColorMap(saliency_map, cv2.COLORMAP_JET)\n",
        "\n",
        "    # Combine image with heatmap\n",
        "    img_with_heatmap = np.float32(color_heatmap) + np.float32(image)\n",
        "    img_with_heatmap = img_with_heatmap / np.max(img_with_heatmap)\n",
        "\n",
        "    cv2.imwrite(filename, np.uint8(255 * img_with_heatmap))"
      ],
      "metadata": {
        "id": "n3_84GyIvO4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model_path='/content/drive/My Drive/DNCNN_logs'\n",
        "data_path = '/content/drive/My Drive/data'\n",
        "dataset = '/Set12'\n",
        "test_noiseL = 25\n",
        "save_path = '/content/drive/My Drive/DNCNN_saliency_maps/full_grad'\n",
        "\n",
        "print('Loading model ...\\n')\n",
        "net = DnCNN(channels=1, num_of_layers=17)\n",
        "device_ids = [0]\n",
        "model = nn.DataParallel(net, device_ids=device_ids).cuda()\n",
        "model.load_state_dict(torch.load(os.path.join(trained_model_path + '/DnCNN-S-25', 'net.pth')))\n",
        "model.eval()\n",
        "# load data info\n",
        "print('Loading data info ...\\n')\n",
        "files_source = glob.glob(os.path.join(data_path + dataset, '*.png'))\n",
        "files_source.sort()\n",
        "\n",
        "\"\"\"\n",
        "data = files_source[0]\n",
        "Img = cv2.imread(data)\n",
        "Img = normalize(np.float32(Img[:,:,0]))\n",
        "Img = np.expand_dims(Img, 0)\n",
        "Img = np.expand_dims(Img, 1)\n",
        "ISource = torch.Tensor(Img)\n",
        "print(ISource.size())\n",
        "\"\"\"\n",
        "\n",
        "saliency_methods = FullGrad(model)\n",
        "\n",
        "def compute_saliency_and_save():\n",
        "    for data in enumerate(files_source):\n",
        "        data = data.to(device).requires_grad_()\n",
        "        Img = cv2.imread(data)\n",
        "        Img = normalize(np.float32(Img[:,:,0]))\n",
        "        Img = np.expand_dims(Img, 0)\n",
        "        Img = np.expand_dims(Img, 1)\n",
        "        ISource = torch.Tensor(Img)\n",
        "        noise = torch.FloatTensor(ISource.size()).normal_(mean=0, std=test_noiseL/255.)\n",
        "        INoisy = ISource + noise\n",
        "        ISource, INoisy = Variable(ISource.cuda()), Variable(INoisy.cuda())\n",
        "\n",
        "        # Compute saliency maps for the input data\n",
        "        saliency_map = saliency_methods.saliency(INoisy)\n",
        "\n",
        "        # Save saliency maps\n",
        "        for i in range(data.size(0)):\n",
        "            filename = str(i)\n",
        "            image = data[i]\n",
        "            save_saliency_map(image, saliency_map[i], filename + '_'  + '.jpg')\n",
        "\n",
        "compute_saliency_and_save()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "0L49c2svjVqT",
        "outputId": "871bf194-0df0-4a59-f627-4abff3158e17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model ...\n",
            "\n",
            "Loading data info ...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-18c49d42fbc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \"\"\"\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0msaliency_methods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFullGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_saliency_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-8c9c08834e8d>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, im_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_ext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFullGradExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetBiases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckCompleteness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheckCompleteness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-8c9c08834e8d>\u001b[0m in \u001b[0;36mcheckCompleteness\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Compute full-gradients and add them up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0minput_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfullGradientDecompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mfullgradient_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_grad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-8c9c08834e8d>\u001b[0m in \u001b[0;36mfullGradientDecompose\u001b[0;34m(self, image, target_class)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# -1 compensates for negation in nll_loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m#output_scalar = -1. * F.nll_loss(out, target_class.flatten(), reduction='sum')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0moutput_scalar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0minput_gradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetFeatureGrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_scalar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2530\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2531\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2532\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected target size [1, 256], got [1, 256, 256]"
          ]
        }
      ]
    }
  ]
}